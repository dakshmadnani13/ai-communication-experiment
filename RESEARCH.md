# When Two AIs Talked to Each Other — A Student Experiment on AI Communication, Computation, and Energy Limits

## Abstract
This paper documents a personal experiment designed to explore whether two artificial intelligence systems could effectively "communicate" to complete a technical task autonomously. Using ChatGPT and Cursor Pro AI, I attempted to create a setup where one model generated instructions for the other to follow, in order to build a sports-bet detection program.  
The experiment began with promising results but ultimately failed due to computational and environmental constraints. The process revealed critical insights into the limitations of large language models (LLMs), the role of energy consumption in AI systems, and the growing importance of efficient prompt engineering.

## 1. Introduction
The rapid evolution of large language models has created new questions about automation, reasoning, and the boundaries of artificial intelligence. This project was inspired by curiosity about whether two advanced AIs could sustain a form of dialogue or cooperation to achieve a shared computational goal — without continuous human intervention.  

The goal was not to build a working sports-bet detector, but to understand how autonomous communication between AIs might behave in practice and what factors limit it.

## 2. Methodology
Using OpenAI’s ChatGPT and Cursor Pro AI (an AI-assisted code editor), I established a feedback loop:  
1. ChatGPT generated technical prompts or design instructions.  
2. Cursor interpreted and executed those prompts to generate or refine code.  
3. The results were then fed back into ChatGPT for the next iteration.  

This setup simulated a minimal form of “AI-to-AI dialogue,” where each model played a role in the same problem-solving pipeline.

## 3. Observations and Failures
The system operated successfully for several iterations but failed to complete the full task.  
The issues encountered were primarily computational, not logical:
- **Context overflow:** Exceeding model memory at roughly 128k tokens.  
- **Container timeout:** Cursor’s cloud sessions automatically terminated after ~45 seconds.  
- **Token-credit exhaustion:** The API limited the total number of processed tokens per billing cycle.

These failures exposed an important reality: even digital intelligence is limited by physical constraints — hardware, energy, and time.

## 4. Technical and Physical Discussion
Each prompt or token generated by an AI triggers GPU operations in massive data centers.  
These operations consume electrical power, generate heat, and require active cooling.  
The efficiency of an AI model is thus not purely a function of algorithmic intelligence, but also of energy management and infrastructure capacity.  

The idea of letting two AIs communicate continuously sounds powerful in theory but becomes exponentially costly in practice. Every “exchange” between models multiplies token usage and compute cycles, making such experiments bound not by code, but by physics.

## 5. Reflections on Energy and Efficiency
This realization shifted my understanding of artificial intelligence from purely logical to fundamentally physical.  
AI models are not just software systems; they are *energy systems*.  
Every interaction has a cost — not only computationally, but environmentally.  

It also became clear that improving prompt design could reduce energy waste by minimizing redundant or inefficient queries. Prompt engineering, therefore, is not just about accuracy — it is about sustainability.

## 6. Implications for Computer Science Students
As a Computer Science student, this experiment forced me to rethink the future of technical education.  
AI will not eliminate human developers. Instead, it will require new kinds of developers — those who understand both computation and optimization.  
The next generation of engineers will need to think about power usage, token efficiency, and data-center scale alongside traditional programming skills.  

Prompt engineering sits at this intersection: it’s where human reasoning guides machine intelligence toward efficient output.

## 7. Conclusion
The experiment began as an attempt to see whether two AIs could collaborate, but it ended as a study of limits — computational, physical, and philosophical.  
It revealed that intelligence itself is constrained by the energy it consumes and that sustainable AI requires more than faster hardware; it requires smarter communication.  

This experiment also reaffirmed my belief that human creativity and curiosity remain irreplaceable. While AI can generate code and respond to queries, it cannot question *why* the process matters. That reasoning — and the drive to explore — is still uniquely human.

## 8. Personal Reflection
This project was co-written and refined using AI assistance, as part of my ongoing journey in prompt engineering and deep learning.  
If you’re reading this, you might even ask yourself — was this written by me or by AI?  
The truth is, it was a collaboration.  
And that’s exactly what I believe the future of computing will look like: humans and AI thinking together, bound by physics but driven by curiosity.

## Author
**Daksh Madnani**  
B.Comp. (Co-op), Computer Science — University of Guelph  
Area of Emphasis: Artificial Intelligence  
Interests: Deep Learning, Prompt Engineering, AI Systems Design, Sustainable Computing  

---

### License
This repository and its contents are intended for educational and research purposes only.
